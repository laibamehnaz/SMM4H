{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk.stem as stm\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "seed = 4353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\hp\\Desktop\\SMM4H_DATASETS\\trn_cls.csv' , header = None )\n",
    "df_train = df_train.rename(columns = { 0 : \"ADR\" ,  1 : \"Tweet\"} )\n",
    "\n",
    "df_val = pd.read_csv(r'C:\\Users\\hp\\Desktop\\SMM4H_DATASETS\\val_cls.csv' , header = None )\n",
    "df_val = df_val.rename(columns = { 0 : \"ADR\" ,  1 : \"Tweet\"} )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def text_len(df):\n",
    "    #i = ['text']\n",
    "    df['num_words'] = df['Tweet'].apply(lambda x: len(str(x).split()))\n",
    "    df['num_uniq_words'] = df['Tweet'].apply(lambda x: len(set(str(x).split())))\n",
    "    df['num_chars'] = df['Tweet'].apply(lambda x: len(str(x)))\n",
    "    df['num_stopwords'] = df['Tweet'].apply(lambda x: len([w for w in str(x).lower().split() \n",
    "                                                          if w in set(stopwords.words('english'))]))\n",
    "    df['num_punctuations'] = df['Tweet'].apply(lambda x: len([w for w in str(x) if w in string.punctuation]))\n",
    "    df['num_words_upper'] = df['Tweet'].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "    df['num_words_title'] = df['Tweet'].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "    df['mean_word_len'] = df['Tweet'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "text_len(df_train)\n",
    "text_len(df_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_uniq_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_words_upper</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>do any of my friends who take pristiq have pro...</td>\n",
       "      <td>friend take pristiq problem nausea?</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>humira helped my crohn s but then respiratory...</td>\n",
       "      <td>humira help crohn respiratori issu ensu amp ta...</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.409091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADR                                              Tweet  \\\n",
       "0  1.0  do any of my friends who take pristiq have pro...   \n",
       "1  1.0   humira helped my crohn s but then respiratory...   \n",
       "\n",
       "                                             cleaned  num_words  \\\n",
       "0                friend take pristiq problem nausea?         12   \n",
       "1  humira help crohn respiratori issu ensu amp ta...         22   \n",
       "\n",
       "   num_uniq_words  num_chars  num_stopwords  num_punctuations  \\\n",
       "0              12         65              7                 1   \n",
       "1              20        119              9                 0   \n",
       "\n",
       "   num_words_upper  num_words_title  mean_word_len  \n",
       "0                0                0       4.416667  \n",
       "1                0                0       4.409091  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Removing stop words\n",
    "stop = stopwords.words('english')\n",
    "df_train['cleaned'] = df_train['Tweet'].apply(lambda x: ' '.join( [ word for word in x.split() if word not in (stop) ] ))\n",
    "df_val['cleaned'] = df_val['Tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "## Stemming \n",
    "stemmer = stm.PorterStemmer()\n",
    "df_train['cleaned'] = df_train['cleaned'].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n",
    "df_val['cleaned'] = df_val['cleaned'].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,3) , stop_words='english')\n",
    "\n",
    "count_vectorized_train = count_vect.fit_transform(df_train.cleaned)\n",
    "count_vectorized_val = count_vect.transform(df_val.cleaned)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "\n",
    "tfidf_vectorized_train = tfidf_vect.fit_transform(df_train.cleaned)\n",
    "tfidf_vectorized_val = tfidf_vect.transform(df_val.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5974, 75761)\n",
      "(3460, 75761)\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorized_train.shape)\n",
    "print(count_vectorized_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5974, 8846)\n",
      "(3460, 8846)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorized_train.shape)\n",
    "print(tfidf_vectorized_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_count = count_vectorized_train\n",
    "y_train_count = df_train.ADR\n",
    "\n",
    "X_test_count = count_vectorized_val\n",
    "y_test_count = df_val.ADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorized_train\n",
    "y_train_tfidf = df_train.ADR\n",
    "\n",
    "X_test_tfidf = tfidf_vectorized_val\n",
    "y_test_tfidf = df_val.ADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5974, 75761)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorized_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5974,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5974, 8846)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorized_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ( without meta features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## COUNT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1\n",
      "0.6932409012131715\n",
      "K =  2\n",
      "0.7114695340501793\n",
      "K =  3\n",
      "0.7198641765704583\n",
      "K =  4\n",
      "0.6954177897574124\n",
      "K =  5\n",
      "0.7291311754684837\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5 , shuffle = True , random_state = seed)\n",
    "pred_val_full = 0\n",
    "cv_score = []\n",
    "i = 1\n",
    "\n",
    "for train_index , test_index in kf.split( X_train_count ):\n",
    "    print(\"K = \" , i)\n",
    "    X_trn , X_val = X_train_count[train_index], X_train_count[test_index]\n",
    "    y_trn , y_val = y_train_count[train_index], y_train_count[test_index]\n",
    "    \n",
    "    model = XGBClassifier(objective='binary:logistic', eval_metric = 'error' , learning_rate = 0.3 , max_depth = 4 ,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 0.8,\n",
    "        min_child_weight =  6,\n",
    "        reg_alpha = 1.5, \n",
    "        reg_lambda = 5,\n",
    "        scale_pos_weight = 1,          \n",
    "        n_thread = -1 ,\n",
    "        gamma = 5)\n",
    "    \n",
    "\n",
    "    model.fit(X_trn, y_trn)    \n",
    "   \n",
    "    y_pred = model.predict(X_val)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    \n",
    "    f1 = f1_score( y_val , predictions , average='binary')\n",
    "    print(f1)\n",
    "    cv_score.append(f1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1_score score on validation set 0.7098247154119411\n"
     ]
    }
   ],
   "source": [
    "print('Mean f1_score score on validation set',np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3421052631578947\n"
     ]
    }
   ],
   "source": [
    "## On validation set\n",
    "\n",
    "y_pred = model.predict(X_test_count)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "f1 = f1_score(y_test_count, predictions)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1\n",
      "0.6944198405668733\n",
      "K =  2\n",
      "0.7133640552995391\n",
      "K =  3\n",
      "0.7084048027444254\n",
      "K =  4\n",
      "0.716549295774648\n",
      "K =  5\n",
      "0.7101321585903083\n"
     ]
    }
   ],
   "source": [
    "## TF IDF\n",
    "\n",
    "kf = KFold(n_splits = 5 , shuffle = True , random_state = seed)\n",
    "pred_val_full = 0\n",
    "cv_score = []\n",
    "i = 1\n",
    "\n",
    "for train_index , test_index in kf.split( X_train_tfidf ):\n",
    "    print(\"K = \" , i)\n",
    "    X_trn , X_val = X_train_tfidf[train_index], X_train_tfidf[test_index]\n",
    "    y_trn , y_val = y_train_tfidf[train_index], y_train_tfidf[test_index]\n",
    "    \n",
    "    model = XGBClassifier(objective='binary:logistic', eval_metric = 'error' , learning_rate = 0.3 , max_depth = 4 ,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 0.8,\n",
    "        min_child_weight =  6,\n",
    "        reg_alpha = 1.5, \n",
    "        reg_lambda = 5,\n",
    "        scale_pos_weight = 1,          \n",
    "        n_thread = -1 ,\n",
    "        gamma = 5)\n",
    "    model.fit(X_trn, y_trn)    \n",
    "   \n",
    "    y_pred = model.predict(X_val)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    \n",
    "    f1 = f1_score( y_val , predictions , average='binary')\n",
    "    print(f1)\n",
    "    cv_score.append(f1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1_score score on validation set 0.7085740305951588\n"
     ]
    }
   ],
   "source": [
    "print('Mean f1_score score on validation set',np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3553054662379421\n"
     ]
    }
   ],
   "source": [
    "## On validation set\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "f1 = f1_score(y_test_tfidf , predictions)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.stem as stm # Import stem class from nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>do any of my friends who take pristiq have pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>humira helped my crohn s but then respiratory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I feel siiiiiiiiiiiiiiick. Damn you venlafaxine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>it is totally stupid withdrawing from temazep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>monique thinks the grapefruit i ate amp latuda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADR                                              Tweet\n",
       "0  1.0  do any of my friends who take pristiq have pro...\n",
       "1  1.0   humira helped my crohn s but then respiratory...\n",
       "2  1.0   I feel siiiiiiiiiiiiiiick. Damn you venlafaxine.\n",
       "3  1.0   it is totally stupid withdrawing from temazep...\n",
       "4  1.0  monique thinks the grapefruit i ate amp latuda..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\hp\\Desktop\\SMM4H_DATASETS\\trn_cls.csv' , header = None )\n",
    "df_train = df_train.rename(columns = { 0 : \"ADR\" ,  1 : \"Tweet\"} )\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>did not know Lamotrigine was addictive Stoppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>i used to dream every night without fail on f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tamiflu has a side effect which includes vomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>DOC for Panic disorders alprazolam addictive a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>taking entyvio now for crohn is since remicad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADR                                              Tweet\n",
       "0  1.0   did not know Lamotrigine was addictive Stoppe...\n",
       "1  1.0   i used to dream every night without fail on f...\n",
       "2  1.0   tamiflu has a side effect which includes vomi...\n",
       "3  1.0  DOC for Panic disorders alprazolam addictive a...\n",
       "4  1.0   taking entyvio now for crohn is since remicad..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(r'C:\\Users\\hp\\Desktop\\SMM4H_DATASETS\\val_cls.csv' , header = None )\n",
    "df_val = df_val.rename(columns = { 0 : \"ADR\" ,  1 : \"Tweet\"} )\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Removing stop words\n",
    "stop = stopwords.words('english')\n",
    "df_train['cleaned'] = df_train['Tweet'].apply(lambda x: ' '.join( [ word for word in x.split() if word not in (stop) ] ))\n",
    "df_val['cleaned'] = df_val['Tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Stemming \n",
    "stemmer = stm.PorterStemmer()\n",
    "df_train['cleaned'] = df_train['cleaned'].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n",
    "df_val['cleaned'] = df_val['cleaned'].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1,3) , stop_words='english')\n",
    "\n",
    "count_vectorized_train = count_vect.fit_transform(df_train.cleaned)\n",
    "count_vectorized_val = count_vect.transform(df_val.cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "\n",
    "tfidf_vectorized_train = tfidf_vect.fit_transform(df_train.cleaned)\n",
    "tfidf_vectorized_val = tfidf_vect.transform(df_val.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5974, 75761)\n",
      "(3460, 75761)\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorized_train.shape)\n",
    "print(count_vectorized_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5974, 8846)\n",
      "(3460, 8846)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorized_train.shape)\n",
    "print(tfidf_vectorized_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_count = count_vectorized_train\n",
    "y_train_count = df_train.ADR\n",
    "\n",
    "X_test_count = count_vectorized_val\n",
    "y_test_count = df_val.ADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorized_train\n",
    "y_train_tfidf = df_train.ADR\n",
    "\n",
    "X_test_tfidf = tfidf_vectorized_val\n",
    "y_test_tfidf = df_val.ADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5974, 75761)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5974"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3460, 75761)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3460"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multinommial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "[0.81024334 0.81860755 0.82762594 0.80876471 0.77690775]\n"
     ]
    }
   ],
   "source": [
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "parameters = {'alpha':[0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "nb_count = MultinomialNB()\n",
    "nb_grid_count = GridSearchCV( nb_count , param_grid = parameters , scoring='f1' , cv = 5 )\n",
    "nb_grid_count.fit(X_train_count, y_train_count)\n",
    "print(nb_grid_count.best_params_)\n",
    "print(nb_grid_count.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7063583815028902\n",
      "0.23813169984686064\n",
      "0.9367469879518072\n",
      "0.3797313797313797\n"
     ]
    }
   ],
   "source": [
    "nb_count = MultinomialNB( alpha = 1.0)\n",
    "nb_count.fit( X_train_count , y_train_count)\n",
    "predictions_count = nb_count.predict(X_test_count)\n",
    "print(accuracy_score(y_test_count, predictions_count))\n",
    "print(precision_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(recall_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(f1_score(y_test_count ,predictions_count, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "[0.79501209 0.80651422 0.81010657 0.79022128 0.77614524]\n"
     ]
    }
   ],
   "source": [
    "### GRID SEARCH FOR TFIDF\n",
    "parameters = {'alpha':[0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_grid_tfidf = GridSearchCV( nb_tfidf , param_grid = parameters , scoring='f1' , cv = 5)\n",
    "nb_grid_tfidf.fit(X_train_tfidf , y_train_tfidf )\n",
    "print(nb_grid_tfidf.best_params_)\n",
    "print(nb_grid_tfidf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6919075144508671\n",
      "0.22855029585798817\n",
      "0.9307228915662651\n",
      "0.3669833729216152\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = MultinomialNB( alpha = 1.0)\n",
    "nb_tfidf.fit( X_train_tfidf , y_train_tfidf )\n",
    "predictions_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "print(accuracy_score(y_test_tfidf , predictions_tfidf ))\n",
    "print(precision_score(y_test_tfidf ,predictions_tfidf , average = 'binary'))\n",
    "print(recall_score(y_test_tfidf ,predictions_tfidf , average = 'binary'))\n",
    "print(f1_score(y_test_tfidf ,predictions_tfidf , average = 'binary'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "[0.75683966 0.76242132 0.81526726 0.83332916 0.83208507 0.82964249]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "parameters = { 'C':[0.001,0.01,0.1,1,10,100] }\n",
    "lr_count = LogisticRegression( penalty = 'l2')\n",
    "lr_grid_count = GridSearchCV( lr_count  ,  parameters ,  scoring = 'f1' , cv = 5)\n",
    "lr_grid_count.fit(X_train_count, y_train_count)\n",
    "print(lr_grid_count.best_params_)\n",
    "print(lr_grid_count.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n",
      "0.3748326639892905\n",
      "0.8433734939759037\n",
      "0.5189990732159407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_count = LogisticRegression( C = 1 , penalty = 'l2')\n",
    "lr_count.fit( X_train_count , y_train_count)\n",
    "predictions_count = lr_count.predict(X_test_count)\n",
    "print(accuracy_score(y_test_count, predictions_count))\n",
    "print(precision_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(recall_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(f1_score(y_test_count ,predictions_count, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n",
      "[0.77313195 0.75181834 0.76015655 0.79418491 0.82340614 0.81973023]\n"
     ]
    }
   ],
   "source": [
    "### GRID SEARCH FOR TFIDF\n",
    "parameters = { 'C':[0.001,0.01,0.1,1,10,100] }\n",
    "\n",
    "lr_tfidf = LogisticRegression( penalty = 'l2')\n",
    "lr_grid_tfidf = GridSearchCV( lr_tfidf  ,  parameters ,  scoring = 'f1' , cv = 5)\n",
    "lr_grid_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "print(lr_grid_tfidf.best_params_)\n",
    "print(lr_grid_tfidf.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8135838150289018\n",
      "0.3231638418079096\n",
      "0.8614457831325302\n",
      "0.47000821692686934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression( C = 10 , penalty = 'l2')\n",
    "lr_tfidf.fit( X_train_tfidf , y_train_tfidf )\n",
    "predictions_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "print(accuracy_score(y_test_tfidf, predictions_tfidf ))\n",
    "print(precision_score(y_test_tfidf ,predictions_tfidf, average='binary'))\n",
    "print(recall_score(y_test_tfidf ,predictions_tfidf, average='binary'))\n",
    "print(f1_score(y_test_tfidf ,predictions_tfidf, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1}\n",
      "[0.56391153 0.66926115 0.56391153 0.67420864 0.54854047 0.79625872\n",
      " 0.78094628 0.80616809]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "\n",
    "Cs = [0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.1, ]\n",
    "parameters = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "svm_count = svm.SVC(kernel = 'rbf')\n",
    "grid_svm_count = GridSearchCV( svm_count , parameters,  scoring = 'f1' , cv = 5)\n",
    "grid_svm_count.fit(X_train_count, y_train_count)\n",
    "print(grid_svm_count.best_params_)\n",
    "print(grid_svm_count.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8713872832369942\n",
      "0.41294298921417566\n",
      "0.8072289156626506\n",
      "0.54638124362895\n"
     ]
    }
   ],
   "source": [
    "svm_count = svm.SVC( C = 10 , gamma =  0.1 , kernel = 'rbf')\n",
    "svm_count.fit( X_train_count , y_train_count)\n",
    "predictions_count = svm_count.predict(X_test_count)\n",
    "print(accuracy_score(y_test_count, predictions_count))\n",
    "print(precision_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(recall_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(f1_score(y_test_count ,predictions_count, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1}\n",
      "[0.48234078 0.50407485 0.48234078 0.50407485 0.48234078 0.75889053\n",
      " 0.48234078 0.82217387]\n"
     ]
    }
   ],
   "source": [
    "### GRID SEARCH FOR TFIDF\n",
    "Cs = [0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.1, ]\n",
    "parameters = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "svm_tfidf = svm.SVC(kernel = 'rbf')\n",
    "grid_svm_tfidf = GridSearchCV( svm_tfidf , parameters,  scoring = 'f1' , cv = 5)\n",
    "grid_svm_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "print(grid_svm_tfidf.best_params_)\n",
    "print(grid_svm_tfidf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8078034682080925\n",
      "0.3160220994475138\n",
      "0.8614457831325302\n",
      "0.46240905416329825\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf = svm.SVC( C = 10 , gamma =  0.1 , kernel = 'rbf')\n",
    "svm_tfidf.fit( X_train_tfidf , y_train_tfidf )\n",
    "predictions_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
    "print(accuracy_score(y_test_tfidf , predictions_tfidf))\n",
    "print(precision_score(y_test_tfidf ,predictions_tfidf, average='binary'))\n",
    "print(recall_score(y_test_tfidf ,predictions_tfidf, average='binary'))\n",
    "print(f1_score(y_test_tfidf ,predictions_tfidf, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "print(min_samples_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'min_samples_split': 150}\n",
      "[0.16721654 0.16721654 0.16721654 0.25766085 0.25766085 0.25728127\n",
      " 0.4031897  0.40209795 0.40365013 0.65979864 0.66270986 0.68063069]\n"
     ]
    }
   ],
   "source": [
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "\n",
    "parameters = {'min_samples_split' : [ 10 , 50 , 150],'max_depth': [1,2, 5 , 20]}\n",
    "\n",
    "tree_count = DecisionTreeClassifier()\n",
    "tree_grid_count = GridSearchCV(tree_count , parameters, scoring = 'f1' , cv = 5)\n",
    "tree_grid_count.fit(X_train_count, y_train_count)\n",
    "print(tree_grid_count.best_params_)\n",
    "print(tree_grid_count.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7341040462427746\n",
      "0.21232876712328766\n",
      "0.6536144578313253\n",
      "0.3205317577548006\n"
     ]
    }
   ],
   "source": [
    "tree_count = DecisionTreeClassifier( max_depth =  20 , min_samples_split = 150 )\n",
    "tree_count.fit( X_train_count , y_train_count )\n",
    "predictions_count_tree = tree_count.predict(X_test_count)\n",
    "\n",
    "print(accuracy_score( y_test_count , predictions_count_tree ))\n",
    "print(precision_score(y_test_count , predictions_count_tree, average = 'binary'))\n",
    "print(recall_score(y_test_count , predictions_count_tree , average = 'binary'))\n",
    "print(f1_score(y_test_count ,predictions_count_tree , average = 'binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'min_samples_split': 150}\n",
      "[0.14002645 0.14002645 0.14002645 0.25720186 0.25720186 0.25720186\n",
      " 0.38183927 0.38160712 0.38350667 0.66098008 0.65877136 0.67037368]\n"
     ]
    }
   ],
   "source": [
    "## GRID SEARCH FOR TF-IDF\n",
    "\n",
    "parameters = {'min_samples_split' : [ 10 , 50 , 150],'max_depth': [1,2, 5 , 20]}\n",
    "\n",
    "tree_tfidf = DecisionTreeClassifier()\n",
    "tree_grid_tfidf = GridSearchCV(tree_tfidf , parameters , scoring = 'f1' , cv = 5)\n",
    "tree_grid_tfidf.fit(X_train_tfidf , y_train_tfidf )\n",
    "print(tree_grid_tfidf.best_params_)\n",
    "print(tree_grid_tfidf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604046242774567\n",
      "0.2223463687150838\n",
      "0.5993975903614458\n",
      "0.3243683781581092\n"
     ]
    }
   ],
   "source": [
    "tree_tfidf = DecisionTreeClassifier( max_depth =  20 , min_samples_split = 150 )\n",
    "tree_tfidf.fit( X_train_tfidf , y_train_tfidf )\n",
    "predictions_tfidf_tree = tree_tfidf.predict( X_test_tfidf )\n",
    "\n",
    "print(accuracy_score( y_test_tfidf , predictions_tfidf_tree ))\n",
    "print(precision_score(y_test_tfidf , predictions_tfidf_tree, average = 'binary'))\n",
    "print(recall_score(y_test_tfidf , predictions_tfidf_tree , average = 'binary'))\n",
    "print(f1_score(y_test_tfidf ,predictions_tfidf_tree , average = 'binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

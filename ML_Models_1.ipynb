{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.stem as stm # Import stem class from nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\hp\\Desktop\\pos.txt\" , encoding=\"utf8\") as f:\n",
    "    pos = f.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3319, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['ADR'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\hp\\Desktop\\neg.txt\" , encoding=\"utf8\") as f:\n",
    "    neg = f.readlines()\n",
    "df2 = pd.DataFrame(neg) \n",
    "df2['ADR'] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1 , df2] , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns = { 0 : \"tweet\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "df['tweet'] = df['tweet'].map(lambda x, tknzr=tknzr: \" \".join(tknzr.tokenize(x))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###shuffling the dataset\n",
    "\n",
    "df_new = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>ADR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little did i know that i would go through with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today amp the past 5 days are so have not been...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So damn sleepy . This seroquel is fucking me u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lmao . i loved geodon until i started passing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just wait for the weight gain to set in . I wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  ADR\n",
       "0  little did i know that i would go through with...    1\n",
       "1  today amp the past 5 days are so have not been...    1\n",
       "2  So damn sleepy . This seroquel is fucking me u...    1\n",
       "3  lmao . i loved geodon until i started passing ...    1\n",
       "4  Just wait for the weight gain to set in . I wa...    1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34592, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df_new[:30000]\n",
    "test = df_new[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = test.ADR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4592"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## Removing stop words\n",
    "stop = stopwords.words('english')\n",
    "train['cleaned'] = train['tweet'].apply(lambda x: ' '.join( [ word for word in x.split() if word not in (stop) ] ))\n",
    "test['cleaned'] = test['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet</th>\n",
       "      <th>ADR</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22691</td>\n",
       "      <td>shrink put us on yet another pill olanzapine ....</td>\n",
       "      <td>0</td>\n",
       "      <td>shrink put us yet another pill olanzapine . sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2971</td>\n",
       "      <td>i hate saphris so much it is the worst thing i...</td>\n",
       "      <td>1</td>\n",
       "      <td>hate saphris much worst thing ever prescribed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              tweet  ADR  \\\n",
       "0  22691  shrink put us on yet another pill olanzapine ....    0   \n",
       "1   2971  i hate saphris so much it is the worst thing i...    1   \n",
       "\n",
       "                                             cleaned  \n",
       "0  shrink put us yet another pill olanzapine . sa...  \n",
       "1  hate saphris much worst thing ever prescribed ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "## Stemming \n",
    "stemmer = stm.PorterStemmer()\n",
    "\n",
    "train['cleaned'] = train['cleaned'].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n",
    "test['cleaned'] = test['cleaned'].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef tokenize_and_stem(text):\\n    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\\n    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\\n    filtered_tokens = []\\n    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\\n    for token in tokens:\\n        if re.search('[a-zA-Z]', token):\\n            filtered_tokens.append(token)\\n    stems = [stemmer.stem(t) for t in filtered_tokens]\\n    return stems\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the count vectorizer with an NGram Range from 1 to 3 and english for stop words.\n",
    "count_vect = CountVectorizer(ngram_range=(1,3),stop_words='english')\n",
    "\n",
    "count_vectorized_train = count_vect.fit_transform(train.cleaned)\n",
    "count_vectorized_test = count_vect.transform(test.cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "\n",
    "tfidf_vectorized_train = tfidf_vect.fit_transform(train.cleaned)\n",
    "tfidf_vectorized_test = tfidf_vect.transform(test.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 290148)\n",
      "(4592, 290148)\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorized_train.shape)\n",
    "print(count_vectorized_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 19747)\n",
      "(4592, 19747)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorized_train.shape)\n",
    "print(tfidf_vectorized_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_count = count_vectorized_train\n",
    "y_train_count = train.ADR\n",
    "\n",
    "X_test_count = count_vectorized_test\n",
    "y_test_count = test.ADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorized_train\n",
    "y_train_tfidf = train.ADR\n",
    "\n",
    "X_test_tfidf = tfidf_vectorized_test\n",
    "y_test_tfidf = test.ADR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models :\n",
    "## 1. Multinommial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "parameters = {'alpha':[0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "nb_count = MultinomialNB()\n",
    "nb_grid_count = GridSearchCV( nb_count , param_grid = parameters , scoring='neg_log_loss')\n",
    "nb_grid_count.fit(X_train_count, y_train_count)\n",
    "nb_grid_count.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRID SEARCH FOR TFIDF\n",
    "\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_grid_tfidf = GridSearchCV( nb_tfidf , param_grid = parameters , scoring='neg_log_loss')\n",
    "nb_grid_tfidf.fit(X_train_tfidf , y_train_tfidf )\n",
    "nb_grid_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COUNT VECTORIZER ( PREDICTIONS )\n",
    "nb_count = MultinomialNB(alpha = 1.0)\n",
    "nb_count.fit(X_train_count, y_train_count)\n",
    "predictions_count = nb_count.predict(X_test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TFIDF ( PREDICTIONS )\n",
    "\n",
    "nb_tfidf = MultinomialNB(alpha = 0.1)\n",
    "nb_tfidf.fit(X_train_tfidf , y_train_tfidf)\n",
    "predictions_tfidf = nb_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorized Words Accuracy : 0.9457752613240418\n",
      "TfIdf Vectorized Words Accuracy: 0.9233449477351916\n"
     ]
    }
   ],
   "source": [
    "## ACCURACY\n",
    "\n",
    "accuracy_count = accuracy_score(y_test_count, predictions_count)\n",
    "accuracy_tfidf = accuracy_score(y_test_tfidf, predictions_tfidf)\n",
    "\n",
    "print('Count Vectorized Words Accuracy :', accuracy_count)\n",
    "print('TfIdf Vectorized Words Accuracy:', accuracy_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958904109589041\n",
      "0.9454545454545454\n"
     ]
    }
   ],
   "source": [
    "## PRECISION\n",
    "\n",
    "print(precision_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(precision_score(y_test_tfidf ,predictions_tfidf, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666667\n",
      "0.2311111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## RECALL\n",
    "print(recall_score( y_test_count , predictions_count , average='binary'))\n",
    "print(recall_score( y_test_tfidf , predictions_tfidf , average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6278026905829597\n",
      "0.3714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "##F1 SCORE\n",
    "\n",
    "print(f1_score( y_test_count , predictions_count , average='binary'))\n",
    "print(f1_score( y_test_tfidf , predictions_tfidf , average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## GRID SEARCH FOR COUNT VECTORIZER\\nparameters = {'n_neighbors':[7,8,9,10]}\\nknn_count = KNeighborsClassifier()\\nknn_grid_count = GridSearchCV( knn_count , param_grid = parameters)\\nknn_grid_count.fit(X_train_count, y_train_count)\\nknn_grid_count.best_params_\\n\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "parameters = {'n_neighbors':[7,8,9,10]}\n",
    "knn_count = KNeighborsClassifier()\n",
    "knn_grid_count = GridSearchCV( knn_count , param_grid = parameters)\n",
    "knn_grid_count.fit(X_train_count, y_train_count)\n",
    "knn_grid_count.best_params_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## GRID SEARCH FOR TFIDF\n",
    "parameters = {'n_neighbors':[7,8,9,10]}\n",
    "knn_tfidf = KNeighborsClassifier()\n",
    "knn_grid_tfidf = GridSearchCV( knn_tfidf , param_grid = parameters)\n",
    "knn_grid_tfidf.fit(X_train_tfidf , y_train_tfidf)\n",
    "knn_grid_tfidf.best_params_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorized Words Accuracy: 0.9020034843205574\n",
      "TfIdf Vectorized Words Accuracy: 0.9113675958188153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_count_kmn = KNeighborsClassifier(n_neighbors=10)\n",
    "model_tfidf_kmn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "model_count_kmn.fit(X_train_count, y_train_count)\n",
    "model_tfidf_kmn.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "predictions_count_kmn = model_count_kmn.predict(X_test_count)\n",
    "predictions_tfidf_kmn = model_tfidf_kmn.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "accuracy_count_kmn = accuracy_score( y_test_count , predictions_count_kmn)\n",
    "accuracy_tfidf_kmn = accuracy_score( y_test_tfidf , predictions_tfidf_kmn)\n",
    "print('Count Vectorized Words Accuracy:', accuracy_count_kmn)\n",
    "print('TfIdf Vectorized Words Accuracy:', accuracy_tfidf_kmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PRECISION FOR COUNT\n",
    "precision_score(y_test_count ,predictions_count_kmn, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8307692307692308"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PRECISION FOR TFIDF\n",
    "precision_score(y_test_tfidf ,predictions_tfidf_kmn, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RECALL FOR COUNT\n",
    "recall_score( y_test_count , predictions_count_kmn , average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RECALL FOR TFIDF\n",
    "recall_score( y_test_tfidf , predictions_tfidf_kmn , average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## F1 SCORE FOR COUNT\n",
    "f1_score( y_test_count , predictions_count_kmn , average='binary')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20970873786407765"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## F1 SCORE FOR TFIDF\n",
    "f1_score( y_test_tfidf , predictions_tfidf_kmn , average='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "parameters = { 'C':[0.001,0.01,0.1,1,10,100] }\n",
    "lr_count = LogisticRegression( penalty = 'l2')\n",
    "clf_count = GridSearchCV( lr_count  ,  parameters)\n",
    "clf_count.fit(X_train_count, y_train_count)\n",
    "clf_count.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 100}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## GRID SEARCH FOR TFIDF\n",
    "parameters = { 'C':[0.001,0.01,0.1,1,10,100] }\n",
    "lr_tfidf = LogisticRegression( penalty = 'l2')\n",
    "clf_tfidf = GridSearchCV( lr_tfidf ,parameters)\n",
    "clf_tfidf.fit(X_train_tfidf , y_train_tfidf )\n",
    "clf_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9398954703832753\n"
     ]
    }
   ],
   "source": [
    "## PREDICTIONS FOR TFIDF\n",
    "\n",
    "lr_tfidf = LogisticRegression( penalty = 'l2' ,  C = 100)\n",
    "lr_tfidf.fit( X_train_tfidf , y_train_tfidf )\n",
    "predictions_tfidf_lr = lr_tfidf.predict(X_test_tfidf)\n",
    "print(accuracy_score( y_test_tfidf , predictions_tfidf_lr ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265625\n",
      "0.62\n",
      "0.6690647482014388\n"
     ]
    }
   ],
   "source": [
    "print(precision_score( y_test_tfidf , predictions_tfidf_lr , average = 'binary'))\n",
    "print(recall_score( y_test_tfidf , predictions_tfidf_lr, average = 'binary'))\n",
    "print(f1_score( y_test_tfidf ,predictions_tfidf_lr , average='binary')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955574912891986\n"
     ]
    }
   ],
   "source": [
    "## PREDICITONS FOR COUNT VECTORIZER\n",
    "\n",
    "lr_count = LogisticRegression( penalty = 'l2' ,  C = 10)\n",
    "lr_count.fit( X_train_count , y_train_count)\n",
    "predictions_count_lr = lr_count.predict(X_test_count)\n",
    "print(accuracy_score( y_test_count , predictions_count_lr ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9270833333333334"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test_count ,predictions_count_lr , average = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5933333333333334"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score( y_test_count ,predictions_count_lr, average = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7235772357723578"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_count ,predictions_count_lr , average='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Decision Trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "parameters = {'min_samples_split' : range(10,500,20),'max_depth': range(1,2,20)}\n",
    "tree_count = DecisionTreeClassifier()\n",
    "tree_grid_count = GridSearchCV(tree_count , parameters)\n",
    "tree_grid_count.fit(X_train_count, y_train_count)\n",
    "tree_grid_count.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GRID SEARCH FOR TFIDF\n",
    "\n",
    "parameters = {'min_samples_split' : range(10,500,20),'max_depth': range(1,2,20)}\n",
    "tree_tfidf = DecisionTreeClassifier()\n",
    "tree_grid_tfidf = GridSearchCV(tree_tfidf , parameters)\n",
    "tree_grid_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "tree_grid_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9063588850174216\n"
     ]
    }
   ],
   "source": [
    "## PREDICTIONS FOR COUNT\n",
    "\n",
    "tree_count = DecisionTreeClassifier( max_depth =  1, min_samples_split = 10 )\n",
    "tree_count.fit( X_train_count , y_train_count )\n",
    "predictions_count_tree = tree_count.predict(X_test_count)\n",
    "print(accuracy_score( y_test_count , predictions_count_tree ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_count.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(tree_count.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7941176470588235\n",
      "0.06\n",
      "0.11157024793388431\n"
     ]
    }
   ],
   "source": [
    "print(precision_score( y_test_count , predictions_count_tree , average = 'binary'))\n",
    "print(recall_score( y_test_count , predictions_count_tree , average = 'binary'))\n",
    "print(f1_score( y_test_count ,predictions_count_tree , average='binary')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9059233449477352\n"
     ]
    }
   ],
   "source": [
    "## PREDICTIONS FOR TFIDF\n",
    "\n",
    "tree_tfidf = DecisionTreeClassifier( max_depth =  1, min_samples_split = 10 )\n",
    "tree_tfidf.fit( X_train_tfidf , y_train_tfidf )\n",
    "predictions_tfidf_tree = tree_tfidf.predict(X_test_tfidf)\n",
    "print(accuracy_score( y_test_tfidf , predictions_tfidf_tree ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78125\n",
      "0.05555555555555555\n",
      "0.10373443983402489\n"
     ]
    }
   ],
   "source": [
    "print(precision_score( y_test_tfidf , predictions_tfidf_tree , average = 'binary'))\n",
    "print(recall_score( y_test_tfidf , predictions_tfidf_tree , average = 'binary'))\n",
    "print(f1_score( y_test_tfidf ,predictions_tfidf_tree , average='binary')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "Cs = [0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.1, ]\n",
    "parameters = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "svm_count = svm.SVC(kernel = 'rbf')\n",
    "grid_svm_count = GridSearchCV( svm_count , parameters)\n",
    "grid_svm_count.fit(X_train_count, y_train_count)\n",
    "grid_svm_count.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import svm\n",
    "## GRID SEARCH FOR COUNT VECTORIZER\n",
    "Cs = [0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.1, ]\n",
    "parameters = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "svm_tfidf = svm.SVC(kernel = 'rbf')\n",
    "grid_svm_tfidf = GridSearchCV( svm_tfidf , parameters)\n",
    "grid_svm_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "grid_svm_tfidf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9501306620209059\n"
     ]
    }
   ],
   "source": [
    "## PREDICTIONS FOR COUNT\n",
    "\n",
    "svm_count = svm.SVC( C = 10 , gamma = 0.1 )\n",
    "svm_count.fit( X_train_count , y_train_count )\n",
    "predictions_count_svm = svm_count.predict(X_test_count)\n",
    "print(accuracy_score( y_test_count , predictions_count_svm ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9366289198606271\n"
     ]
    }
   ],
   "source": [
    "## PREDICTIONS FOR TFIDF\n",
    "\n",
    "svm_tfidf = svm.SVC( C = 10 , gamma = 0.1 )\n",
    "svm_tfidf.fit( X_train_tfidf , y_train_tfidf )\n",
    "predictions_tfidf_svm = svm_tfidf.predict(X_test_tfidf)\n",
    "print(accuracy_score( y_test_tfidf , predictions_tfidf_svm ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9169811320754717\n",
      "0.54\n",
      "0.6797202797202798\n"
     ]
    }
   ],
   "source": [
    "print(precision_score( y_test_count , predictions_count_svm , average = 'binary'))\n",
    "print(recall_score( y_test_count , predictions_count_svm , average = 'binary'))\n",
    "print(f1_score( y_test_count ,predictions_count_svm , average='binary')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872498266697481\n",
      "0.7291576801330544\n",
      "0.779323191863043\n"
     ]
    }
   ],
   "source": [
    "print(precision_score( y_test_count , predictions_tfidf_svm , average = 'macro'))\n",
    "print(recall_score( y_test_count , predictions_tfidf_svm , average = 'macro'))\n",
    "print(f1_score( y_test_count ,predictions_tfidf_svm , average='macro')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

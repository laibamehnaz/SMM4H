{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk.stem as stm\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "seed = 4353\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\hp\\Desktop\\SMM4H_DATASETS\\trn_cls.csv' , header = None )\n",
    "df_train = df_train.rename(columns = { 0 : \"ADR\" ,  1 : \"Tweet\"} )\n",
    "\n",
    "df_val = pd.read_csv(r'C:\\Users\\hp\\Desktop\\SMM4H_DATASETS\\val_cls.csv' , header = None )\n",
    "df_val = df_val.rename(columns = { 0 : \"ADR\" ,  1 : \"Tweet\"} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Removing stop words\n",
    "stop = stopwords.words('english')\n",
    "df_train['cleaned'] = df_train['Tweet'].apply(lambda x: ' '.join( [ word for word in x.split() if word not in (stop) ] ))\n",
    "df_val['cleaned'] = df_val['Tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "## Stemming \n",
    "stemmer = stm.PorterStemmer()\n",
    "df_train['cleaned'] = df_train['cleaned'].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n",
    "df_val['cleaned'] = df_val['cleaned'].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1,3) , stop_words='english')\n",
    "\n",
    "count_vectorized_train = count_vect.fit_transform(df_train.cleaned)\n",
    "count_vectorized_val = count_vect.transform(df_val.cleaned)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "\n",
    "tfidf_vectorized_train = tfidf_vect.fit_transform(df_train.cleaned)\n",
    "tfidf_vectorized_val = tfidf_vect.transform(df_val.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5974, 75761)\n",
      "(3460, 75761)\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorized_train.shape)\n",
    "print(count_vectorized_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5974, 8846)\n",
      "(3460, 8846)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorized_train.shape)\n",
    "print(tfidf_vectorized_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_count = count_vectorized_train\n",
    "y_train_count = df_train.ADR\n",
    "\n",
    "X_test_count = count_vectorized_val\n",
    "y_test_count = df_val.ADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorized_train\n",
    "y_train_tfidf = df_train.ADR\n",
    "\n",
    "X_test_tfidf = tfidf_vectorized_val\n",
    "y_test_tfidf = df_val.ADR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON VALIDATION SET : \n",
      "0.8306559571619813\n",
      "ON TEST SET : \n",
      "0.8384393063583815\n",
      "0.34805890227576974\n",
      "0.7831325301204819\n",
      "0.48192771084337355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## FOR COOUNT VECTORIZER \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_count, y_train_count , random_state = 0)\n",
    "\n",
    "lr_count = LogisticRegression( C = 100 , penalty = 'l2')\n",
    "lr_count.fit( X_train , y_train)\n",
    "##on validation set\n",
    "predictions_count = lr_count.predict(X_val)\n",
    "print(\"ON VALIDATION SET : \")\n",
    "print(accuracy_score(y_val , predictions_count))\n",
    "\n",
    "## on test set\n",
    "predictions_count = lr_count.predict(X_test_count)\n",
    "print(\"ON TEST SET : \")\n",
    "print(accuracy_score(y_test_count, predictions_count))\n",
    "print(precision_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(recall_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(f1_score(y_test_count ,predictions_count, average='binary'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON VALIDATION SET : \n",
      "0.821285140562249\n",
      "ON TEST SET :\n",
      "0.8317919075144509\n",
      "0.33638743455497383\n",
      "0.7740963855421686\n",
      "0.468978102189781\n"
     ]
    }
   ],
   "source": [
    "## FOR COOUNT VECTORIZER \n",
    "from sklearn import svm\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_count, y_train_count , random_state = 0)\n",
    "\n",
    "svm_count = svm.SVC( C = 100 , gamma =  0.1 , kernel = 'linear')\n",
    "svm_count.fit( X_train , y_train )\n",
    "\n",
    "##on validation set\n",
    "predictions_count = svm_count.predict( X_val )\n",
    "print(\"ON VALIDATION SET : \")\n",
    "print(accuracy_score( y_val , predictions_count))\n",
    "\n",
    "## on test set\n",
    "print(\"ON TEST SET :\")\n",
    "predictions_count = svm_count.predict(X_test_count)\n",
    "print(accuracy_score(y_test_count, predictions_count))\n",
    "print(precision_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(recall_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(f1_score(y_test_count ,predictions_count, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON VALIDATION SET : \n",
      "0.7965194109772423\n",
      "ON TEST SET :\n",
      "0.7083815028901734\n",
      "0.22941646682653877\n",
      "0.8644578313253012\n",
      "0.36260265319014534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_count, y_train_count , random_state = 0)\n",
    "\n",
    "nb_count = MultinomialNB( alpha = 0.01 )\n",
    "nb_count.fit( X_train , y_train )\n",
    "\n",
    "#On validation set\n",
    "predictions_count = nb_count.predict( X_val )\n",
    "print(\"ON VALIDATION SET : \")\n",
    "print(accuracy_score( y_val , predictions_count))\n",
    "\n",
    "## on test set\n",
    "predictions_count = nb_count.predict(X_test_count)\n",
    "print(\"ON TEST SET :\")\n",
    "print(accuracy_score(y_test_count, predictions_count))\n",
    "print(precision_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(recall_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(f1_score(y_test_count ,predictions_count, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON VALIDATION SET : \n",
      "0.8273092369477911\n",
      "ON TEST SET :\n",
      "0.8378612716763005\n",
      "0.34993446920052423\n",
      "0.8042168674698795\n",
      "0.4876712328767123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vclf = VotingClassifier( estimators = [ ('clf1' , LogisticRegression(C = 100 , dual = False) ) , ( 'clf2' , svm.SVC(C = 100 , gamma = 0.1 , kernel = 'rbf', probability = True ) ) , ( 'clf3' , MultinomialNB( alpha = 0.01 ) ) ] , voting = 'soft' )\n",
    "vclf.fit(X_train , y_train)\n",
    "\n",
    "predictions_count = vclf.predict( X_val )\n",
    "print(\"ON VALIDATION SET : \")\n",
    "print(accuracy_score( y_val , predictions_count))\n",
    "\n",
    "## on test set\n",
    "print(\"ON TEST SET :\")\n",
    "predictions_count = vclf.predict(X_test_count)\n",
    "print(accuracy_score(y_test_count, predictions_count))\n",
    "print(precision_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(recall_score(y_test_count ,predictions_count, average='binary'))\n",
    "print(f1_score(y_test_count ,predictions_count, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split( X_train_tfidf , y_train_tfidf , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4480, 8846)\n",
      "ON VALIDATION SET : \n",
      "0.8259705488621151\n",
      "ON TEST SET :\n",
      "0.7893063583815029\n",
      "0.28905419766206164\n",
      "0.8192771084337349\n",
      "0.4273369992144541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vclf = VotingClassifier( estimators = [ ('clf1' , LogisticRegression(C = 100 , dual = False) ) , ( 'clf2' , svm.SVC(C = 100 , gamma = 0.1 , kernel = 'rbf', probability = True ) ) , ( 'clf3' , MultinomialNB( alpha = 0.01 ) ) ] , voting = 'soft' )\n",
    "vclf.fit(X_train , y_train)\n",
    "\n",
    "predictions_count = vclf.predict( X_val )\n",
    "print(\"ON VALIDATION SET : \")\n",
    "print(accuracy_score( y_val , predictions_count))\n",
    "\n",
    "## on test set\n",
    "print(\"ON TEST SET :\")\n",
    "predictions_tfidf = vclf.predict( X_test_tfidf )\n",
    "print(accuracy_score(y_test_tfidf , predictions_tfidf ))\n",
    "print(precision_score(y_test_tfidf ,predictions_tfidf, average='binary'))\n",
    "print(recall_score(y_test_tfidf ,predictions_tfidf, average='binary'))\n",
    "print(f1_score(y_test_tfidf  ,predictions_tfidf, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON VALIDATION SET : \n",
      "0.8279785809906292\n",
      "ON TEST SET :\n",
      "0.7985549132947977\n",
      "0.2996706915477497\n",
      "0.822289156626506\n",
      "0.43925985518905875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier , RandomForestClassifier\n",
    "\n",
    "model = AdaBoostClassifier(RandomForestClassifier(n_estimators = 1000),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators = 100 )\n",
    "model.fit(X_train , y_train)\n",
    "predictions_tfidf = model.predict( X_val )\n",
    "print(\"ON VALIDATION SET : \")\n",
    "print(accuracy_score( y_val , predictions_tfidf))\n",
    "\n",
    "## on test set\n",
    "print(\"ON TEST SET :\")\n",
    "predictions_tfidf = model.predict( X_test_tfidf )\n",
    "print(accuracy_score(y_test_tfidf , predictions_tfidf ))\n",
    "print(precision_score(y_test_tfidf ,predictions_tfidf, average='binary'))\n",
    "print(recall_score(y_test_tfidf ,predictions_tfidf, average='binary'))\n",
    "print(f1_score(y_test_tfidf  ,predictions_tfidf, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
